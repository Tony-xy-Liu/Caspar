{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "# os.environ['LMDB_FORCE_CFFI'] = '1'\n",
    "# # CFFI variant is loaded.\n",
    "import lmdb\n",
    "from txyl_common.biocyc_facade.pgdb import Pgdb, Dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgdb_dir = Path(\"/home/tony/workspace/grad/cpsc445-project/data/txyl_local/biocyc_facade_pgdbs\")\n",
    "\n",
    "pmeta = Pgdb(pgdb_dir.joinpath(\"meta26_0.1_2\"))\n",
    "emeta = Pgdb(pgdb_dir.joinpath(\"eco26_0.1_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = lmdb.open(\"./cache/biocyc_test.lmdb\", map_size=16*1024**3)\n",
    "\n",
    "with env.begin(write=True) as txn:\n",
    "    ENC = \"utf-8\"\n",
    "    for d in Dat:\n",
    "        table = pmeta.GetDataTable(d)\n",
    "        for k, v in table.items():\n",
    "            txn.put(\n",
    "                k.encode(ENC),\n",
    "                json.dumps(v, separators=(\",\",\":\")).encode(ENC)\n",
    "            )\n",
    "\n",
    "    for d in Dat:\n",
    "        table = emeta.GetDataTable(d)\n",
    "        for k, v in table.items():\n",
    "            txn.put(\n",
    "                k.encode(ENC),\n",
    "                json.dumps(v, separators=(\",\",\":\")).encode(ENC)\n",
    "            )\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = lmdb.open(\"./cache/meta_test.lmdb\", map_size=16*1024**3)\n",
    "\n",
    "with env.begin(write=True) as txn:\n",
    "    ENC = \"utf-8\"\n",
    "    for d in Dat:\n",
    "        table = pmeta.GetDataTable(d)\n",
    "        for k, v in table.items():\n",
    "            txn.put(\n",
    "                k.encode(ENC),\n",
    "                json.dumps(v, separators=(\",\",\":\")).encode(ENC)\n",
    "            )\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = lmdb.open(\"./cache/eco_test.lmdb\", map_size=16*1024**3, max_dbs=16)\n",
    "\n",
    "ENC = \"utf-8\"\n",
    "for d in Dat:\n",
    "    namespace = env.open_db(d.name.encode(ENC), create=True)\n",
    "    with env.begin(write=True, db=namespace) as txn:\n",
    "        table = emeta.GetDataTable(d)\n",
    "        for k, v in table.items():\n",
    "            txn.put(\n",
    "                k.encode(ENC),\n",
    "                json.dumps(v, separators=(\",\",\":\")).encode(ENC)\n",
    "            )\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3052"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = lmdb.open(\"./cache/eco_test.lmdb\", map_size=16*1024**3, max_dbs=16)\n",
    "ENC = \"utf-8\"\n",
    "rtable = env.open_db(Dat.REACTIONS.name.encode(ENC))\n",
    "\n",
    "all_entries = []\n",
    "try:\n",
    "    with env.begin() as txn:\n",
    "        ENC = \"utf-8\"\n",
    "        # cur = txn.cursor()\n",
    "        cur = txn.cursor(rtable)\n",
    "        for k, v in cur:\n",
    "            all_entries.append((\n",
    "                k.decode(ENC),\n",
    "                json.loads(v.decode(ENC))\n",
    "            ))\n",
    "finally:\n",
    "    env.close()\n",
    "len(all_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = lmdb.open(\"./cache/eco_test.lmdb\", map_size=16*1024**3, max_dbs=16)\n",
    "ENC = \"utf-8\"\n",
    "rtable = env.open_db(Dat.REACTIONS.name.encode(ENC))\n",
    "\n",
    "all_entries = []\n",
    "try:\n",
    "    with env.begin() as txn:\n",
    "        ENC = \"utf-8\"\n",
    "        # cur = txn.cursor()\n",
    "        cur = txn.cursor(rtable)\n",
    "        for k, v in cur:\n",
    "            print(k.decode(ENC), v.decode(\"utf-8\"))\n",
    "            # break\n",
    "            # all_entries.append((\n",
    "            #     k.decode(ENC),\n",
    "            #     json.loads(v.decode(ENC))\n",
    "            # ))\n",
    "finally:\n",
    "    env.close()\n",
    "len(all_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = lmdb.open(\"./cache/lmdb_test.lmdb\", map_size=16*1024**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'test_key' b'{\"x\":1,\"b\":\"Asdf\",\"inner\":{\"ix\":2},\"array\":[1,2,3,4]}'\n"
     ]
    }
   ],
   "source": [
    "with env.begin() as txn:\n",
    "    cursor = txn.cursor()\n",
    "    for k, v in cursor:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = {\n",
    "    \"x\": 1,\n",
    "    \"b\": \"Asdf\",\n",
    "    \"inner\": {\n",
    "        \"ix\": 2,\n",
    "    },\n",
    "    \"array\": [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "with env.begin(write=True) as transaction:\n",
    "    sdata = json.dumps(test_data, separators=(',',':'))\n",
    "    bdata = sdata.encode(\"utf-8\")\n",
    "    key = \"test_key\"\n",
    "    bkey = key.encode(\"utf-8\")\n",
    "    transaction.put(bkey, bdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with env.begin() as transaction:\n",
    "    _bdata: bytes = transaction.get(bkey)\n",
    "    out = json.loads(_bdata.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 1, 'b': 'Asdf', 'inner': {'ix': 2}, 'array': [1, 2, 3, 4]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
